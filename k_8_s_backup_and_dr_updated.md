# ğŸš€ Kubernetes Production Cluster Setup
### Installation, Backup & Disaster Recovery with kubeadm

A complete, productionâ€‘grade guide for deploying Kubernetes on AWS using **kubeadm**, including **Backup + Disaster Recovery (DR)** best practices.

---

## 1ï¸âƒ£ Introduction
This guide helps you:
- ğŸ¯ Deploy a Kubernetes cluster using kubeadm on AWS
- ğŸ” Back up critical Kubernetes components
- ğŸ”„ Restore and recover the cluster during a failure

### ğŸ§° Prerequisites
- ğŸ§ Ubuntu 20.04 or later
- ğŸ§‘â€ğŸ’» `sudo` privileges
- ğŸŒ Internet access
- ğŸ’» EC2 instance type: t2.medium or higher

### â˜ï¸ AWS Setup Overview
- ğŸ›¡ All nodes in **same Security Group**
- ğŸ§© Create + attach a **custom ENI** with static private IP
- ğŸ”“ Open inbound ports:
  - 22 (SSH) ğŸ”‘
  - 6443 (Kubernetes API) ğŸ”

---

## 2ï¸âƒ£ Kubernetes Installation & Cluster Setup

### ğŸŒ AWS Networking Preparation
Before creating the Master node:
1. ğŸ§© Create ENI
2. ğŸ” Assign static private IP
3. ğŸ”— Attach ENI to Master
4. â–¶ Use ENI private IP for `kubeadm init`

> ğŸ”¹ Prevents IP/cert conflicts during DR

---

### ğŸ”„ Common Setup (Master & Worker Nodes)
Run on **all nodes** ğŸ‘‡

#### ğŸ”• Disable Swap
```bash
sudo swapoff -a
```

#### ğŸ”§ Load Kernel Modules
```bash
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter
```

#### ğŸŒ Apply Sysctl Params
```bash
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF
sudo sysctl --system
```

#### ğŸ“¦ Install containerd
```bash
sudo apt-get update
sudo apt-get install -y ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt-get update
sudo apt-get install -y containerd.io

containerd config default | sed -e 's/SystemdCgroup = false/SystemdCgroup = true/' | sudo tee /etc/containerd/config.toml
sudo systemctl restart containerd
sudo systemctl enable --now containerd
```

#### ğŸš€ Install Kubernetes Components (v1.29)
```bash
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl

sudo curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | \
sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /" | \
sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl etcd-client
sudo apt-mark hold kubelet kubeadm kubectl
```
> ğŸ”¹ All nodes must run SAME Kubernetes versions!

---

### ğŸ–¥ Master Node Setup
#### ğŸ· Set Hostname
```bash
sudo hostnamectl set-hostname master-cp
echo "127.0.0.1 master-cp" | sudo tee -a /etc/hosts
```
> âš ï¸ Required for Disaster Recovery

#### ğŸš€ Initialize the Control Plane
```bash
sudo kubeadm init --apiserver-advertise-address=<ENI-PRIVATE-IP> --pod-network-cidr=192.168.0.0/16
```

#### ğŸ”‘ Configure kubeconfig
```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

#### ğŸŒ Install CNI (Calico)
```bash
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.0/manifests/calico.yaml
```

#### ğŸ”— Get Worker Join Command
```bash
kubeadm token create --print-join-command
```

---

### ğŸ‘· Worker Node Setup
Add:
- `sudo` at beginning
- `--v=5` at end

Example:
```bash
sudo kubeadm join <ENI-IP>:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash> --cri-socket "unix:///run/containerd/containerd.sock" --v=5
```

---

### ğŸ” Verify Nodes
```bash
kubectl get nodes -o wide
```
âœ” All should be **Ready**

---

## 3ï¸âƒ£ Backup Strategy (Master Only)
### ğŸ“¦ What to Backup
| Component | Path | Purpose |
|----------|------|---------|
| ğŸ’¾ ETCD Snapshot | `/var/lib/etcd` | Cluster state |
| ğŸ” Kubernetes Configs | `/etc/kubernetes/` | API certs & configs |
| ğŸ†” Kubelet Identity | `/var/lib/kubelet` | Node certificates |

#### âº Take ETCD Snapshot
```bash
sudo ETCDCTL_API=3 etcdctl snapshot save /root/k8s-backup/etcd.db \
 --endpoints=https://127.0.0.1:2379 \
 --cacert=/etc/kubernetes/pki/etcd/ca.crt \
 --cert=/etc/kubernetes/pki/etcd/server.crt \
 --key=/etc/kubernetes/pki/etcd/server.key
```

#### ğŸ—‚ Backup configs
```bash
sudo mkdir -p /root/k8s-backup
sudo cp -r /etc/kubernetes /root/k8s-backup/kubernetes
sudo cp -r /var/lib/kubelet /root/k8s-backup/kubelet
sudo -i
cd /root
sudo tar czf k8s-backup.tar.gz k8s-backup
```

#### â˜ Upload to S3
> ğŸ”¹ If this EC2 instance has an **IAM Role** with S3 permissions â€” **NO** `aws configure` is required
> ğŸ”¹ If restoring from a laptop or nonâ€‘role instance â€” run `aws configure` first

**AWS Credential Requirements**
| Environment | Need `aws configure`? | Why |
|------------|:--------------------:|-----|
| EC2 with IAM Role | âŒ No | Auto temporary credentials âœ” |
| EC2 w/out IAM Role | âœ… Yes | No automatic credentials |
| Laptop / external machine | âœ… Yes | Needs manual keys |

```bash
aws s3 cp /root/k8s-backup.tar.gz s3://<bucket>/k8s-backups/$(date +%F-%H%M).tar.gz
```
```bash
aws s3 cp /root/k8s-backup.tar.gz s3://<bucket>/k8s-backups/$(date +%F-%H%M).tar.gz
```
> ğŸ”¹ Requires AWS CLI & IAM role with S3 permissions

---

## 4ï¸âƒ£ Disaster Recovery â€” Master Failure
Launch replacement Master with:
- Same ENI âš™ï¸
- Same hostname ğŸ·

#### ğŸ“¥ Download Backup
```bash
aws s3 cp s3://<bucket>/k8s-backups/<file>.tar.gz /root/k8s-backup.tar.gz
```

#### ğŸ”„ Restore Data
```bash
sudo systemctl stop kubelet
sudo rm -rf /var/lib/etcd
sudo ETCDCTL_API=3 etcdctl snapshot restore /root/k8s-backup/etcd.db --data-dir=/var/lib/etcd
sudo tar xzf /root/k8s-backup.tar.gz -C /
sudo systemctl restart kubelet
```

#### ğŸ” Validate Recovery
```bash
kubectl get nodes -o wide
kubectl get pods -A
kubectl get svc -A
```
âœ” Cluster restored automatically in 30â€“60 sec

---

## 5ï¸âƒ£ Final Production Checklist
| Category | Required |
|---------|:-------:|
| Swap disabled | âœ”ï¸ |
| Static ENI private IP | âœ”ï¸ |
| Same hostname (`master-cp`) | âœ”ï¸ |
| Same Kubernetes versions | âœ”ï¸ |
| Backup stored safely | âœ”ï¸ |
| No `kubeadm init` during DR | âœ”ï¸ |
| Nodes Ready after restore | âœ”ï¸ |

---

## ğŸ¯ Conclusion
You now have:
- ğŸ” Highly available cluster design
- ğŸ’¾ Reliable backup workflow
- ğŸ”„ Fully tested DR procedure

âœ¨ You're productionâ€‘ready!

